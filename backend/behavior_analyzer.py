"""
üß† Behavior Analyzer - ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏à‡∏≤‡∏Å Pose Estimation
‡πÉ‡∏ä‡πâ YOLOv8-pose ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ó‡πà‡∏≤‡∏ó‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°
"""
from ultralytics import YOLO
import numpy as np
import cv2

# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLOv8-pose
pose_model = None

def get_pose_model():
    """‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• pose estimation (lazy loading)"""
    global pose_model
    if pose_model is None:
        pose_model = YOLO("yolov8n-pose.pt")
    return pose_model


def analyze_pose(keypoints):
    """
    ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ó‡πà‡∏≤‡∏ó‡∏≤‡∏á‡∏à‡∏≤‡∏Å keypoints
    
    Keypoints index (COCO format):
    0: nose, 1: left_eye, 2: right_eye, 3: left_ear, 4: right_ear
    5: left_shoulder, 6: right_shoulder, 7: left_elbow, 8: right_elbow
    9: left_wrist, 10: right_wrist, 11: left_hip, 12: right_hip
    13: left_knee, 14: right_knee, 15: left_ankle, 16: right_ankle
    
    Returns:
        dict: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°‡∏ó‡∏µ‡πà‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏î‡πâ
    """
    if keypoints is None or len(keypoints) < 17:
        return {"behavior": "unknown", "confidence": 0, "details": {}}
    
    # ‡∏î‡∏∂‡∏á‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á keypoints ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
    nose = keypoints[0][:2] if keypoints[0][2] > 0.3 else None
    left_eye = keypoints[1][:2] if keypoints[1][2] > 0.3 else None
    right_eye = keypoints[2][:2] if keypoints[2][2] > 0.3 else None
    left_shoulder = keypoints[5][:2] if keypoints[5][2] > 0.3 else None
    right_shoulder = keypoints[6][:2] if keypoints[6][2] > 0.3 else None
    
    behavior = "unknown"
    confidence = 0
    details = {}
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏°‡∏∏‡∏°‡∏Å‡πâ‡∏°‡∏®‡∏µ‡∏£‡∏©‡∏∞
    if nose is not None and left_shoulder is not None and right_shoulder is not None:
        # ‡∏´‡∏≤‡∏à‡∏∏‡∏î‡∏Å‡∏∂‡πà‡∏á‡∏Å‡∏•‡∏≤‡∏á‡πÑ‡∏´‡∏•‡πà
        shoulder_center = np.array([
            (left_shoulder[0] + right_shoulder[0]) / 2,
            (left_shoulder[1] + right_shoulder[1]) / 2
        ])
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á‡∏Ç‡∏≠‡∏á‡∏´‡∏±‡∏ß‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡πÑ‡∏´‡∏•‡πà
        head_height = shoulder_center[1] - nose[1]
        shoulder_width = abs(right_shoulder[0] - left_shoulder[0])
        
        if shoulder_width > 0:
            head_ratio = head_height / shoulder_width
            details["head_ratio"] = round(float(head_ratio), 2)
            
            # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ó‡πà‡∏≤‡∏ó‡∏≤‡∏á
            if head_ratio < 0.3:
                # ‡∏´‡∏±‡∏ß‡∏ï‡πà‡∏≥‡∏°‡∏≤‡∏Å - ‡∏≠‡∏≤‡∏à‡∏´‡∏•‡∏±‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡πâ‡∏°‡∏î‡∏π‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå
                behavior = "sleeping"
                confidence = min(95, int((0.3 - head_ratio) * 200 + 60))
            elif head_ratio < 0.5:
                # ‡∏Å‡πâ‡∏°‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢
                behavior = "looking_down"
                confidence = min(90, int((0.5 - head_ratio) * 150 + 50))
            elif head_ratio < 0.8:
                # ‡∏ó‡πà‡∏≤‡∏ó‡∏≤‡∏á‡∏õ‡∏Å‡∏ï‡∏¥ - ‡∏ï‡∏±‡πâ‡∏á‡πÉ‡∏à‡πÄ‡∏£‡∏µ‡∏¢‡∏ô
                behavior = "attentive"
                confidence = min(95, int(head_ratio * 80 + 30))
            else:
                # ‡∏ô‡∏±‡πà‡∏á‡∏ï‡∏£‡∏á‡∏°‡∏≤‡∏Å
                behavior = "attentive"
                confidence = 90
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (‡πÉ‡∏ä‡πâ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ï‡∏≤)
    if left_eye is not None and right_eye is not None:
        eye_level = (left_eye[1] + right_eye[1]) / 2
        eye_distance = abs(right_eye[0] - left_eye[0])
        details["eye_distance"] = round(float(eye_distance), 2)
        
        # ‡∏ñ‡πâ‡∏≤‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏ï‡∏≤‡πÅ‡∏Ñ‡∏ö‡∏°‡∏≤‡∏Å = ‡∏´‡∏±‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏≠‡∏≠‡∏Å‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡πâ‡∏≤‡∏á
        if eye_distance < 10 and behavior == "attentive":
            behavior = "looking_away"
            confidence = 70
    
    return {
        "behavior": behavior,
        "confidence": confidence,
        "details": details
    }


def analyze_frame(frame):
    """
    ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πâ‡∏á‡πÄ‡∏ü‡∏£‡∏°
    
    Args:
        frame: ‡∏†‡∏≤‡∏û (numpy array ‡∏´‡∏£‡∏∑‡∏≠ path)
    
    Returns:
        dict: ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    """
    model = get_pose_model()
    results = model(frame, verbose=False)
    
    if len(results) == 0 or results[0].keypoints is None:
        return {
            "total_people": 0,
            "behaviors": {},
            "summary": {
                "attentive": 0,
                "sleeping": 0,
                "looking_down": 0,
                "looking_away": 0,
                "unknown": 0
            },
            "attention_rate": 0,
            "annotated_frame": frame if isinstance(frame, np.ndarray) else None
        }
    
    keypoints_data = results[0].keypoints.data.cpu().numpy()
    boxes = results[0].boxes
    
    behaviors = []
    behavior_counts = {
        "attentive": 0,
        "sleeping": 0,
        "looking_down": 0,
        "looking_away": 0,
        "unknown": 0
    }
    
    for i, kp in enumerate(keypoints_data):
        analysis = analyze_pose(kp)
        behaviors.append(analysis)
        
        if analysis["behavior"] in behavior_counts:
            behavior_counts[analysis["behavior"]] += 1
    
    total_people = len(behaviors)
    attention_rate = 0
    if total_people > 0:
        attentive_count = behavior_counts["attentive"]
        attention_rate = round((attentive_count / total_people) * 100, 1)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏°‡∏µ annotation
    annotated_frame = results[0].plot()
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏° label ‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°‡∏ö‡∏ô‡∏†‡∏≤‡∏û
    if boxes is not None and len(boxes) > 0:
        for i, (box, behavior) in enumerate(zip(boxes, behaviors)):
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            
            # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏µ‡∏ï‡∏≤‡∏°‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°
            color = (0, 255, 0)  # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß = ‡∏ï‡∏±‡πâ‡∏á‡πÉ‡∏à
            if behavior["behavior"] == "sleeping":
                color = (0, 0, 255)  # ‡πÅ‡∏î‡∏á = ‡∏´‡∏•‡∏±‡∏ö
            elif behavior["behavior"] == "looking_down":
                color = (0, 165, 255)  # ‡∏™‡πâ‡∏° = ‡∏Å‡πâ‡∏°‡∏´‡∏ô‡πâ‡∏≤
            elif behavior["behavior"] == "looking_away":
                color = (0, 255, 255)  # ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á = ‡∏°‡∏≠‡∏á‡∏≠‡∏≠‡∏Å
            
            # ‡∏ß‡∏≤‡∏î label
            label = get_behavior_label_th(behavior["behavior"])
            cv2.putText(annotated_frame, f"{label} {behavior['confidence']}%", 
                       (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
    
    return {
        "total_people": total_people,
        "behaviors": behaviors,
        "summary": behavior_counts,
        "attention_rate": attention_rate,
        "annotated_frame": annotated_frame
    }


def get_behavior_label_th(behavior):
    """‡πÅ‡∏õ‡∏•‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢"""
    labels = {
        "attentive": "‡∏ï‡∏±‡πâ‡∏á‡πÉ‡∏à‡πÄ‡∏£‡∏µ‡∏¢‡∏ô",
        "sleeping": "‡∏´‡∏•‡∏±‡∏ö",
        "looking_down": "‡∏Å‡πâ‡∏°‡∏´‡∏ô‡πâ‡∏≤",
        "looking_away": "‡∏°‡∏≠‡∏á‡∏≠‡∏≠‡∏Å",
        "unknown": "‡πÑ‡∏°‡πà‡∏ó‡∏£‡∏≤‡∏ö"
    }
    return labels.get(behavior, behavior)


def get_behavior_label_en(behavior):
    """‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ label ‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©"""
    labels = {
        "attentive": "Attentive",
        "sleeping": "Sleeping",
        "looking_down": "Looking Down",
        "looking_away": "Looking Away",
        "unknown": "Unknown"
    }
    return labels.get(behavior, behavior)
